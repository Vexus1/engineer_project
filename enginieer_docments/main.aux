\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Wstęp}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Wprowadzenie do uczenia maszynowego}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Podział uczenia maszynowego}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Uczenie nadzorowane}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Uczenie nienadzorowane}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Uczenie częściowo nadzorowane}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Uczenie przez wzmacnianie}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Teoretyczne podstawy uczenia przez wzmacnianie}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Podstawowe pojęcia i definicje}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Modele Markowa (MDP)}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Proces Markowa z nagrodami}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Równanie Bellmana}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Równanie Bellmana dla funkcji wartości stanu \( V^\pi (s) \)}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Równanie Bellmana dla funkcji wartości akcji \( Q^\pi (s,a) \)}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Równanie Bellmana dla polityki optymalnej \( V^*(s) \) i \( Q^*(s,a) \)}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Metoda iteracji wartości}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.5}Metoda iteracji polityki}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Metoda entropii krzyżowej w uczeniu przez wzmacnianie}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Twierdzenie o próbkowaniu istotnościowym}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Dywergencja Kullbacka-Leiblera}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Implementacjia wybranych algorytmów uczenia przez wzmacnianie}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Klasyfikacja algorytmów uczenia przez wzmacnianie}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Algorytmy optymalizujące wartości (Value optimization)}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Algorytmy optymalizujące politkę (Policy Optimization)}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Algorytmy imitacyjne (imitation)}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Wybór algorytmów do implementacji}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Dlaczego odrzucono klasyczną metodę Q-Learning?}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Deep Q-Learning (DQN)}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Architektura modelu}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Przykładowa architektura sieci Q dla DQN}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Proces treningu algorytmu DQN}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Zalety i wady DQN}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Advantage Actor-Critic (A2C)}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Architektura modelu}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Proces treningu algorytmu A2C}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Zaleti i wady A2C}{12}{}\protected@file@percent }
\gdef \@abspage@last{12}
